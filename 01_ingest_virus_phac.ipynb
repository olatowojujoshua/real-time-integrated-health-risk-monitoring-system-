{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb92fc2-dad6-4f9e-8733-bb5418541f51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 01_ingest_virus_phac - Cell 1\n",
    "\n",
    "SCHEMA_NAME = \"resp_health_db\"  # same as in 00_setup_and_tables\n",
    "\n",
    "spark.sql(f\"USE {SCHEMA_NAME}\")\n",
    "print(\"Current schema:\", spark.sql(\"SELECT current_database()\").first()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5a15262-81d2-4b5c-a5b8-bd27191478d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "SCHEMA_NAME = \"resp_health_db\"\n",
    "spark.sql(f\"USE {SCHEMA_NAME}\")\n",
    "\n",
    "raw_df = spark.table(\"lab_virus_raw\")\n",
    "\n",
    "display(raw_df.limit(10))\n",
    "print(\"Columns:\", raw_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbcda230-22aa-448c-8173-f3ded8b79141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = raw_df.withColumnRenamed(\"Week ending date\", \"week_ending_date\") \\\n",
    "           .withColumnRenamed(\"Percent of tests positive\", \"percent_positive\")\n",
    "\n",
    "clean_df = (\n",
    "    df\n",
    "    .withColumn(\"source_level\", F.lit(\"national\"))\n",
    "    .withColumn(\"data_source\", F.lit(\"PHAC_Laboratory\"))\n",
    "    .withColumn(\"report_date\", F.to_date(F.col(\"week_ending_date\")))\n",
    "    .withColumn(\"province\", F.col(\"Jurisdiction\"))          # usually 'Canada'\n",
    "    .withColumn(\"virus_type\", F.col(\"Virus\").cast(\"string\"))\n",
    "    .withColumn(\"metric_type\", F.lit(\"percent_positive\"))\n",
    "    .withColumn(\"metric_value\", F.col(\"percent_positive\").cast(\"double\"))\n",
    "    .withColumn(\"created_at\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"source_level\",\n",
    "        \"data_source\",\n",
    "        \"report_date\",\n",
    "        \"province\",\n",
    "        \"virus_type\",\n",
    "        \"metric_type\",\n",
    "        \"metric_value\",\n",
    "        \"created_at\"\n",
    "    )\n",
    "    .where(F.col(\"report_date\").isNotNull())\n",
    ")\n",
    "\n",
    "display(clean_df.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04187eba-7cdc-4018-a1d3-896368a457e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clean_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"respiratory_activity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcffa3e3-ac51-4be5-b518-a9f1952d4314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM respiratory_activity LIMIT 20\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaf2e345-621c-4153-86ba-30c3bc4610ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "SCHEMA_NAME = \"resp_health_db\"\n",
    "spark.sql(f\"USE {SCHEMA_NAME}\")\n",
    "\n",
    "clinical_raw = spark.table(\"clinical_virus_raw\")\n",
    "\n",
    "display(clinical_raw.limit(10))\n",
    "print(\"Columns:\", clinical_raw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb54d699-8d5b-44b7-9998-9bca237b497b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clinical_df = clinical_raw.withColumnRenamed(\"Week ending date\", \"week_ending_date\")\n",
    "\n",
    "clinical_clean = (\n",
    "    clinical_df\n",
    "    .withColumn(\"source_level\", F.lit(\"national\"))\n",
    "    .withColumn(\"data_source\", F.lit(\"PHAC_Clinical\"))\n",
    "    .withColumn(\"report_date\", F.to_date(F.col(\"week_ending_date\")))\n",
    "    .withColumn(\"province\", F.col(\"Jurisdiction\"))\n",
    "    .withColumn(\"virus_type\", F.col(\"Virus\").cast(\"string\"))\n",
    "    .withColumn(\"metric_type\", F.col(\"Measure\").cast(\"string\"))   # e.g. 'Outbreaks'\n",
    "    .withColumn(\"metric_value\", F.col(\"Count\").cast(\"double\"))\n",
    "    .withColumn(\"created_at\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"source_level\",\n",
    "        \"data_source\",\n",
    "        \"report_date\",\n",
    "        \"province\",\n",
    "        \"virus_type\",\n",
    "        \"metric_type\",\n",
    "        \"metric_value\",\n",
    "        \"created_at\"\n",
    "    )\n",
    "    .where(F.col(\"report_date\").isNotNull())\n",
    ")\n",
    "\n",
    "display(clinical_clean.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a475fddd-a816-4441-b80b-be7b659983fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "clinical_clean.write.format(\"delta\").mode(\"append\").saveAsTable(\"respiratory_activity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4860432b-cd42-4781-a889-94c1048b195c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT source_level, data_source, report_date, province, virus_type, metric_type, metric_value\n",
    "FROM respiratory_activity\n",
    "ORDER BY report_date DESC\n",
    "LIMIT 30\n",
    "\"\"\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_ingest_virus_phac",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
